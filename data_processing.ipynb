{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhGUfAu72sQoKxWYr4zDfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akbarroyhan69-gif/running-pace-analyst-/blob/main/data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "NmZRWW4Pm0w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kXQtRpNomyjd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Unggah Dataset ke Google Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "O-mKxiktjYX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "q2Rfu_24sBUR",
        "outputId": "7f45fcd3-4c1c-4c86-e7c8-acfec58c1ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08075d22-e328-4cd2-aa25-2343ed9ee80d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08075d22-e328-4cd2-aa25-2343ed9ee80d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving s.xlsx to s.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini digunakan modul files dari google.colab untuk melakukan proses unggah (upload) dataset ke lingkungan Google Colab. Perintah files.upload() memungkinkan peneliti mengunggah file dataset secara langsung dari perangkat lokal ke sesi Colab yang sedang digunakan.\n",
        "Dataset yang diunggah merupakan data hasil kuesioner mahasiswa Universitas Darussalam (UNIDA) yang berisi variabel-variabel yang berkaitan dengan karakteristik mahasiswa dan kebiasaan aktivitas lari, yang selanjutnya digunakan dalam analisis dan pemodelan pace lari. Setelah proses unggah dilakukan, file tersebut akan tersimpan sementara di direktori kerja Colab dan dapat diakses menggunakan library pandas untuk tahap pengolahan data berikutnya.\n",
        "Tahap ini sangat penting karena menjadi langkah awal dalam integrasi data penelitian ke dalam sistem, sehingga seluruh proses pembersihan data, analisis, dan pembangunan model Random Forest dapat dilakukan secara terstruktur dan sistematis."
      ],
      "metadata": {
        "id": "Xwma8RsRj0SM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membaca dan Membersihkan Dataset"
      ],
      "metadata": {
        "id": "5ABcnB16jjmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B32yp6OvvgMe"
      },
      "outputs": [],
      "source": [
        "d=pd.read_excel('s.xlsx')\n",
        "d=d.dropna(how='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan proses pembacaan dataset penelitian menggunakan fungsi read_excel() dari library pandas. File s.xlsx merupakan dataset yang berisi data hasil kuesioner mahasiswa Universitas Darussalam (UNIDA) yang mencakup berbagai variabel yang berkaitan dengan karakteristik individu dan kebiasaan aktivitas lari mahasiswa, yang digunakan sebagai dasar analisis pace lari.\n",
        "\n",
        "Selanjutnya, dilakukan proses pembersihan data dengan menggunakan perintah dropna(how='all'). Perintah ini bertujuan untuk menghapus baris data yang seluruh nilai pada kolomnya kosong (missing values). Langkah ini dilakukan untuk memastikan bahwa hanya data yang memiliki informasi relevan yang digunakan dalam proses analisis dan pemodelan, sehingga dapat meningkatkan kualitas dataset dan mengurangi potensi gangguan dalam proses pelatihan model."
      ],
      "metadata": {
        "id": "cFjFpc2NjppV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standarisasi Format Data"
      ],
      "metadata": {
        "id": "CQHpgoIGj7sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d[\"pace\"] = d[\"pace\"].astype(str).str.replace(\",\", \".\")\n",
        "d[\"semester\"] = d[\"semester\"].astype(str).str.replace(\"semester\",\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hZNY6eICj7Wk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan proses standarisasi dan penyesuaian format data pada beberapa variabel penting agar dapat diproses secara numerik oleh sistem machine learning.\n",
        "\n",
        "Baris kode d[\"pace\"] = d[\"pace\"].astype(str).str.replace(\",\", \".\") digunakan untuk mengubah nilai pada variabel pace lari ke dalam format teks sementara, kemudian mengganti tanda koma (,) menjadi tanda titik (.). Langkah ini dilakukan karena perbedaan format penulisan desimal pada data kuesioner, sehingga perlu diseragamkan agar nilai pace dapat dikonversi ke bentuk numerik secara benar pada tahap selanjutnya.\n",
        "\n",
        "Selanjutnya, baris kode d[\"semester\"] = d[\"semester\"].astype(str).str.replace(\"semester\",\"\") digunakan untuk membersihkan variabel semester dengan menghapus teks non-numerik “semester”. Proses ini bertujuan agar nilai semester hanya berisi angka, sehingga dapat digunakan sebagai variabel numerik dalam analisis dan pemodelan."
      ],
      "metadata": {
        "id": "lJX7d-3pkE7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Konversi Tipe Data dan Penanganan Nilai Kosong\n"
      ],
      "metadata": {
        "id": "BFPsONu2kNZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi tipe numeric\n",
        "num_cols = [\"semester\", \"usia\", \"tinggi\", \"latihan_per_minggu\", \"berat\", \"pace\", \"perokok\"]\n",
        "\n",
        "for col in num_cols:\n",
        "    d[col] = pd.to_numeric(d[col], errors=\"coerce\")\n",
        "\n",
        "# Kolom int (kecuali pace dan perokok)\n",
        "cols_to_int = [col for col in num_cols if col not in ['pace', 'perokok']]\n",
        "\n",
        "# Tangani NaN\n",
        "d[cols_to_int] = d[cols_to_int].fillna(0).astype('int64')\n",
        "\n",
        "# Ubah perokok menjadi boolean\n",
        "d['perokok'] = d['perokok'].fillna(0).astype(bool)"
      ],
      "metadata": {
        "id": "NkwrMHATkMvJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pada tahap ini dilakukan proses konversi tipe data numerik serta penanganan nilai kosong (missing values) pada dataset hasil kuesioner mahasiswa Universitas Darussalam (UNIDA). Proses ini bertujuan untuk memastikan seluruh variabel dapat diproses dengan baik oleh algoritma machine learning.\n",
        "\n",
        "*   Variabel yang bersifat numerik, yaitu semester, usia, tinggi badan, frekuensi latihan per minggu, berat badan, pace lari, dan status perokok, dikonversi ke tipe numerik menggunakan fungsi to_numeric() dengan parameter errors=\"coerce\". Parameter ini berfungsi untuk mengubah nilai yang tidak dapat dikonversi menjadi numerik menjadi nilai kosong (NaN), sehingga memudahkan proses pembersihan data selanjutnya.\n",
        "*   Selanjutnya, dilakukan pemisahan kolom yang akan dikonversi ke tipe bilangan bulat (integer), yaitu seluruh variabel numerik kecuali pace lari dan status perokok. Nilai kosong pada kolom-kolom tersebut diisi dengan nilai nol, kemudian dikonversi ke tipe data int64. Langkah ini dilakukan karena variabel seperti semester, usia, tinggi badan, berat badan, dan frekuensi latihan secara konseptual merupakan data diskrit.\n",
        "\n",
        "\n",
        "*   Untuk variabel status perokok, nilai kosong diisi dengan nol dan kemudian dikonversi ke tipe data boolean (True/False). Konversi ini bertujuan untuk merepresentasikan status perokok sebagai variabel biner, sehingga lebih sesuai untuk digunakan dalam proses pemodelan dan analisis faktor yang memengaruhi pace lari mahasiswa.\n",
        "\n",
        "Tahap konversi tipe data dan penanganan nilai kosong ini merupakan bagian penting dari data preprocessing, karena memastikan konsistensi dan validitas data, serta meningkatkan keandalan model Random Forest dalam menganalisis dan memprediksi pace lari mahasiswa UNIDA.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hl3s_VvrkToJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perhitungan Indeks Massa Tubuh (IMT)"
      ],
      "metadata": {
        "id": "_q-xDsSEkhXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rh2hiaVUJ0A4"
      },
      "outputs": [],
      "source": [
        "d['tinggi_m'] = d['tinggi'] / 100\n",
        "d['imt'] = d['berat'] / (d['tinggi_m'] ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan proses pembentukan variabel turunan (feature engineering) berupa Indeks Massa Tubuh (IMT) yang digunakan untuk menggambarkan komposisi tubuh mahasiswa.\n",
        "\n",
        "Baris kode d['tinggi_m'] = d['tinggi'] / 100 digunakan untuk mengonversi tinggi badan mahasiswa dari satuan sentimeter ke meter. Konversi ini diperlukan agar perhitungan IMT dapat dilakukan sesuai dengan rumus standar yang menggunakan satuan meter.\n",
        "\n",
        "Selanjutnya, baris kode d['imt'] = d['berat'] / (d['tinggi_m'] ** 2) digunakan untuk menghitung nilai Indeks Massa Tubuh dengan membagi berat badan (kilogram) dengan kuadrat tinggi badan (meter). Nilai IMT yang dihasilkan mencerminkan proporsi berat badan terhadap tinggi badan dan digunakan sebagai salah satu variabel independen dalam analisis faktor-faktor yang memengaruhi pace lari mahasiswa Universitas Darussalam (UNIDA).\n",
        "\n",
        "Pembentukan variabel IMT ini bertujuan untuk memperkaya informasi dalam dataset dan membantu model Random Forest dalam menangkap hubungan antara kondisi fisik mahasiswa dengan performa lari, khususnya dalam hal pace lari.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_gHim2NlThl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentasi Data"
      ],
      "metadata": {
        "id": "MvrhIveEldWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# AUGMENTASI\n",
        "# ---------------------------\n",
        "def augment_row(row, n=5):\n",
        "    augmented = []\n",
        "    for _ in range(n):\n",
        "        new_row = row.copy()\n",
        "        new_row[\"pace\"] += np.random.uniform(0, 0.3)\n",
        "        new_row[\"pace\"] = round(new_row[\"pace\"], 2)\n",
        "        new_row[\"berat\"] += np.random.randint(0, 5)\n",
        "        augmented.append(new_row)\n",
        "    return augmented\n",
        "\n",
        "augmented_rows = []\n",
        "for i in range(len(d)):\n",
        "    augmented_rows.extend(augment_row(d.iloc[i], n=5))\n",
        "\n",
        "augmented_df = pd.DataFrame(augmented_rows)"
      ],
      "metadata": {
        "id": "9kx6zrVelt5s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan augmentasi data untuk meningkatkan jumlah dan variasi data latih yang digunakan dalam pemodelan pace lari mahasiswa Universitas Darussalam (UNIDA). Augmentasi data dilakukan karena jumlah data asli relatif terbatas, sehingga diperlukan penambahan variasi data sintetis agar model Random Forest dapat belajar dengan lebih baik dan mengurangi risiko overfitting.\n",
        "\n",
        "Fungsi augment_row() digunakan untuk menghasilkan beberapa data baru dari satu baris data asli. Pada setiap proses augmentasi, nilai pace lari dimodifikasi dengan menambahkan nilai acak kecil dalam rentang 0 hingga 0,3 menit per kilometer. Penambahan ini bertujuan untuk mensimulasikan variasi alami performa lari mahasiswa yang dapat dipengaruhi oleh kondisi fisik dan lingkungan. Nilai pace kemudian dibulatkan hingga dua angka desimal agar tetap realistis.\n",
        "\n",
        "Selain itu, nilai berat badan juga dimodifikasi dengan menambahkan bilangan bulat acak antara 0 hingga 4 kilogram. Perubahan ini dimaksudkan untuk merepresentasikan variasi ringan pada berat badan mahasiswa yang masih berada dalam rentang wajar dan dapat terjadi dalam kondisi nyata, misalnya akibat perbedaan waktu pengukuran atau kondisi tubuh.\n",
        "\n",
        "Proses augmentasi dilakukan sebanyak lima kali untuk setiap data asli, sehingga setiap entri data menghasilkan lima data baru. Seluruh data hasil augmentasi kemudian digabungkan ke dalam sebuah DataFrame baru (augmented_df) yang digunakan sebagai dataset tambahan dalam proses pemodelan.\n",
        "\n",
        "Selanjutnya, dilakukan pembentukan variabel target kategori pace, yaitu cepat dan lambat. Kategori cepat diberikan untuk nilai pace kurang dari 5 menit per kilometer, sedangkan kategori lambat diberikan untuk nilai pace sama dengan atau lebih dari 5 menit per kilometer. Pengelompokan ini digunakan untuk mendukung analisis klasifikasi pace lari mahasiswa.\n",
        "\n",
        "Tahap augmentasi data ini berperan penting dalam meningkatkan keberagaman data, memperkuat kemampuan generalisasi model Random Forest, serta menghasilkan model yang lebih stabil dan andal dalam menganalisis faktor-faktor yang memengaruhi pace lari mahasiswa UNIDA."
      ],
      "metadata": {
        "id": "y560yuUHl6i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Penggabungan Data Asli dan Data Hasil Augmentasi"
      ],
      "metadata": {
        "id": "g90OrMGvmFNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = pd.concat([d, augmented_df], ignore_index=True)\n",
        "full_df = full_df.dropna()"
      ],
      "metadata": {
        "id": "GNOk9Ae7lzFN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dilakukan proses penggabungan dataset asli dengan dataset hasil augmentasi untuk membentuk dataset akhir yang digunakan dalam proses pemodelan. Penggabungan dilakukan menggunakan fungsi pd.concat() dengan parameter ignore_index=True, sehingga seluruh data, baik data asli maupun data hasil augmentasi, disatukan dalam satu struktur data tanpa mempertahankan indeks lama.\n",
        "\n",
        "Dataset gabungan (full_df) kemudian melalui proses pembersihan lanjutan dengan menggunakan fungsi dropna(). Langkah ini bertujuan untuk menghapus baris data yang masih mengandung nilai kosong (missing values) setelah proses penggabungan, sehingga dataset akhir hanya berisi data yang lengkap dan valid.\n",
        "\n",
        "Tahap ini sangat penting karena memastikan bahwa model Random Forest dilatih menggunakan dataset yang lebih besar, lebih bervariasi, dan bebas dari nilai kosong. Dengan demikian, kualitas data latih meningkat, risiko kesalahan dalam proses pelatihan model dapat diminimalkan, serta hasil analisis faktor-faktor yang memengaruhi pace lari mahasiswa Universitas Darussalam (UNIDA) menjadi lebih akurat dan dapat diandalkan."
      ],
      "metadata": {
        "id": "B-UuLrv-mGvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df.to_csv(\"full_df.csv\", index=False)\n",
        "d.to_csv(\"data_d.csv\", index=False)"
      ],
      "metadata": {
        "id": "4lCy1K1tR9fq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"full_df.csv\")\n",
        "files.download(\"data_d.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rUvQLjZITGiO",
        "outputId": "1427d9b9-bbfd-4916-e697-f2afa1b879c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1f5e7b1-858f-468f-aa5e-7f61a42152c8\", \"full_df.csv\", 107390)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a488171-5779-4de9-99e9-42f9b6fbbf8e\", \"data_d.csv\", 17959)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}